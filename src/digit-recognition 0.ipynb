{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6Irhawl5s6I"
      },
      "source": [
        "# Digit Recognition\n",
        "\n",
        "Build a deep learning model to classify handwritten digits. You can use convolutional neural networks (CNNs) or other machine learning algorithms for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ARQ4D0bK5s6L",
        "outputId": "d9e5eb04-cb94-4982-e47c-e88696e5ed12"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries for PyTorch and data visualization\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE0z-Nrs5s6M"
      },
      "source": [
        "## Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amsvF2sR5s6M"
      },
      "outputs": [],
      "source": [
        "# Create useful folders\n",
        "folders = [\"../data\", \"../results/\", \"../results/digit-recognition/\"]\n",
        "for f in folders:\n",
        "    if not os.path.exists(f):\n",
        "        os.mkdir(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qsalMD6-5s6N",
        "outputId": "886b1ec2-25f6-42d2-ffb1-660cb57a9745"
      },
      "outputs": [],
      "source": [
        "# Defining batch sizes for training and testing data\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "\n",
        "# Defining data transformations, including converting images to tensors and normalizing pixel values\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        ")\n",
        "\n",
        "# Loading MNIST dataset for training and testing\n",
        "# For training data, setting train=True, downloading if not available, and applying transformations\n",
        "train_dataset = datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n",
        "\n",
        "# For testing data, setting train=False, not downloading, and applying transformations\n",
        "test_dataset = datasets.MNIST(\"../data\", train=False, transform=transform)\n",
        "\n",
        "# Creating data loaders for efficient batch processing during training and testing\n",
        "# For training data, using DataLoader with specified batch size and shuffling the data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size_train, shuffle=True\n",
        ")\n",
        "\n",
        "# For testing data, using DataLoader with specified batch size and shuffling the data\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size_test, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1411
        },
        "id": "YAutSodR5s6N",
        "outputId": "b1877aad-cfcf-47bf-d3dc-afbbce003dcc"
      },
      "outputs": [],
      "source": [
        "# Getting one batch of examples from the test_loader\n",
        "batch_idx, (example_data, example_targets) = next(enumerate(test_loader))\n",
        "\n",
        "# Printing the shape of the example_data tensor\n",
        "print(\"Shape of example_data:\", example_data.shape)\n",
        "\n",
        "# Plotting the first images along with their labels\n",
        "fig, axes = plt.subplots(5, 5, figsize=(10, 15))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(example_data[i][0], cmap=\"gray\", interpolation=\"none\")\n",
        "    ax.set_title(\"{}\".format(example_targets[i]))\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8voMKfcm5s6N"
      },
      "source": [
        "## Building the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWZOpAia5s6N"
      },
      "outputs": [],
      "source": [
        "class AlexNetMNIST(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNetMNIST, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1), # Taille de sortie : (batch_size, 64, 14, 14)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2), # Taille de sortie : (batch_size, 64, 7, 7)\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1), # Taille de sortie : (batch_size, 192, 7, 7)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2), # Taille de sortie : (batch_size, 192, 3, 3)\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1), # Taille de sortie : (batch_size, 384, 3, 3)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1), # Taille de sortie : (batch_size, 256, 3, 3)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1), # Taille de sortie : (batch_size, 256, 3, 3)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2), # Taille de sortie : (batch_size, 256, 1, 1)\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((3, 3))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 3 * 3, 1024), # Taille de sortie : (batch_size, 1024)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, 512), # Taille de sortie : (batch_size, 512)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, num_classes), # Taille de sortie : (batch_size, num_classes)\n",
        "        )\n",
        "        # Initialiser les poids\n",
        "        self._initialize_weights()\n",
        "        \n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init.constant_(m.weight, 1)\n",
        "                init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                init.normal_(m.weight, 0, 0.01)\n",
        "                init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rdMOB6kj5s6O",
        "outputId": "1da12bf6-39eb-41cc-a418-d7ac9c321643"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1\n",
        "n_epochs = 3\n",
        "train_losses = []\n",
        "\n",
        "# Create an instance of the model\n",
        "model = AlexNetMNIST()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiYX-q7_5s6O"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import shutil\n",
        "\n",
        "# Path to the log directory\n",
        "log_dir = \"./runs/digit-recognition/\"\n",
        "\n",
        "# Remove the previous log directory (if it exists)\n",
        "shutil.rmtree(log_dir, ignore_errors=True)\n",
        "\n",
        "# Initialize TensorBoard writer\n",
        "writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "# Visualize the network architecture\n",
        "dummy_input = torch.rand(1, 1, 28, 28)  # Create a dummy input tensor\n",
        "writer.add_graph(model, dummy_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ru10PQ75s6O"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv9vS0-m5s6P"
      },
      "outputs": [],
      "source": [
        "log_interval = 50\n",
        "n1 = len(train_loader.dataset)\n",
        "n2 = len(train_loader)\n",
        "def train(epoch):\n",
        "    \"\"\"\n",
        "    Training function for the neural network model.\n",
        "\n",
        "    Args:\n",
        "        epoch (int): Current epoch number.\n",
        "    \"\"\"\n",
        "    model.train()  # Set the model to training mode\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        output = model(data)  # Forward pass\n",
        "        loss = criterion(output, target)  # Calculate the loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        # Print training progress and store losses\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\n",
        "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "                    epoch,\n",
        "                    batch_idx * len(data),\n",
        "                    n1,\n",
        "                    100.0 * batch_idx / n2,\n",
        "                    loss.item(),\n",
        "                )\n",
        "            )\n",
        "            train_losses.append(loss.item())\n",
        "    # Save model and optimizer states at the end of each epoch\n",
        "    torch.save(model.state_dict(), '../results/digit-recognition/model_epoch_{}.pth'.format(epoch))\n",
        "    torch.save(optimizer.state_dict(), '../results/digit-recognition/optimizer_epoch_{}.pth'.format(epoch))\n",
        "\n",
        "def test():\n",
        "    \"\"\"\n",
        "    Evaluation function for the neural network model on the test set.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)  # Forward pass\n",
        "            test_loss += criterion(\n",
        "                output, target, reduction=\"sum\"\n",
        "            ).item()  # Calculate the loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the predicted labels\n",
        "            correct += (\n",
        "                pred.eq(target.view_as(pred)).sum().item()\n",
        "            )  # Count correct predictions\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    # Print test set results\n",
        "    print(\n",
        "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
        "            test_loss,\n",
        "            correct,\n",
        "            len(test_loader.dataset),\n",
        "            100.0 * correct / len(test_loader.dataset),\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JSyWgMTx5s6P",
        "outputId": "21fd2091-a005-4dd6-d6c2-af312c4da7a0"
      },
      "outputs": [],
      "source": [
        "# Training and testing loop\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    train(epoch)  # Train the model for the current epoch\n",
        "    test()  # Evaluate the model on the test set after training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnKQRUqx5s6P"
      },
      "source": [
        "## Evaluating the Model's Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "f7n89yq45s6P",
        "outputId": "1500c116-a6eb-4abd-dbb3-c354da027d94"
      },
      "outputs": [],
      "source": [
        "# Create a new figure for plotting\n",
        "fig = plt.figure()\n",
        "\n",
        "# Plot training losses as a blue line\n",
        "plt.plot(train_losses, color=\"blue\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Add legend and labels\n",
        "plt.legend([\"Train Loss\"], loc=\"upper right\")\n",
        "plt.xlabel(\"Number of training examples seen\")\n",
        "plt.ylabel(\"Negative log likelihood loss\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        },
        "id": "L6uug9-p5s6Q",
        "outputId": "cb5b600b-4dd2-4bcc-8bcb-9151d6addf5e"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    # Disable gradient calculation\n",
        "    output = model(example_data)  # Forward pass of the model with example_data\n",
        "    fig, axes = plt.subplots(5, 5, figsize=(10, 15))  # Create a 3x4 grid of subplots\n",
        "    predictions = output.argmax(dim=1)  # Calculate predictions once\n",
        "\n",
        "    # Iterate over each subplot\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(example_data[i][0], cmap=\"gray\", interpolation=\"none\")\n",
        "        prediction = predictions[i].item()\n",
        "        target = example_targets[i].item()\n",
        "        ax.set_title(f\"pred={prediction}, real={target}\", color='green' if prediction == target else 'red')\n",
        "        ax.axis('off')  # Hide axis labels\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
