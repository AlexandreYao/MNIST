{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for PyTorch and data visualization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Setting a random seed for reproducibility\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False  # Disabling CuDNN for deterministic results\n",
    "_ = torch.manual_seed(random_seed)  # Setting manual seed for random number generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining batch sizes for training and testing data\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "# Defining data transformations, including converting images to tensors and normalizing pixel values\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "# Loading MNIST dataset for training and testing\n",
    "# For training data, setting train=True, downloading if not available, and applying transformations\n",
    "dataset1 = datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n",
    "\n",
    "# For testing data, setting train=False, not downloading, and applying transformations\n",
    "dataset2 = datasets.MNIST(\"../data\", train=False, transform=transform)\n",
    "\n",
    "# Creating data loaders for efficient batch processing during training and testing\n",
    "# For training data, using DataLoader with specified batch size and shuffling the data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset1, batch_size=batch_size_train, shuffle=True\n",
    ")\n",
    "\n",
    "# For testing data, using DataLoader with specified batch size and shuffling the data\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset2, batch_size=batch_size_test, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting one batch of examples from the test_loader\n",
    "batch_idx, (example_data, example_targets) = next(enumerate(test_loader))\n",
    "\n",
    "# Printing the shape of the example_data tensor\n",
    "print(\"Shape of example_data:\", example_data.shape)\n",
    "\n",
    "# Plotting the first 6 images along with their labels\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(example_data[i][0], cmap=\"gray\", interpolation=\"none\")\n",
    "    ax.set_title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Define convolutional layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "        \n",
    "        # Define fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(9216, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_layers(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1\n",
    "model = Net()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "train_losses = []\n",
    "train_counter = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 50\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    \"\"\"\n",
    "    Training function for the neural network model.\n",
    "\n",
    "    Args:\n",
    "        epoch (int): Current epoch number.\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        output = model(data)  # Forward pass\n",
    "        loss = F.nll_loss(output, target)  # Calculate the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        # Print training progress and store losses\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx * len(data)) + ((epoch - 1) * len(train_loader.dataset))\n",
    "            )\n",
    "    # Save model and optimizer states at the end of each epoch\n",
    "    torch.save(model.state_dict(), '../results/model_epoch_{}.pth'.format(epoch))\n",
    "    torch.save(optimizer.state_dict(), '../results/optimizer_epoch_{}.pth'.format(epoch))\n",
    "\n",
    "def test():\n",
    "    \"\"\"\n",
    "    Evaluation function for the neural network model on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)  # Forward pass\n",
    "            test_loss += F.nll_loss(\n",
    "                output, target, reduction=\"sum\"\n",
    "            ).item()  # Calculate the loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the predicted labels\n",
    "            correct += (\n",
    "                pred.eq(target.view_as(pred)).sum().item()\n",
    "            )  # Count correct predictions\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # Print test set results\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing loop\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)  # Train the model for the current epoch\n",
    "    test()  # Evaluate the model on the test set after training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_counter = [i * len(train_loader.dataset) for i in range(n_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure for plotting\n",
    "fig = plt.figure()\n",
    "\n",
    "# Plot training losses as a blue line\n",
    "plt.plot(train_counter, train_losses, color=\"blue\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend([\"Train Loss\"], loc=\"upper right\")\n",
    "plt.xlabel(\"Number of training examples seen\")\n",
    "plt.ylabel(\"Negative log likelihood loss\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Disable gradient calculation\n",
    "    output = model(example_data)  # Forward pass of the model with example_data\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 6))  # Create a 2x3 grid of subplots\n",
    "    predictions = output.data.max(1, keepdim=True)[1]  # Calculate predictions once\n",
    "    # Iterate over each subplot\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(example_data[i][0], cmap=\"gray\", interpolation=\"none\")\n",
    "        ax.set_title(\"Prediction: {}\".format(predictions[i].item()))\n",
    "        ax.axis('off')  # Hide axis labels\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
